{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKSHOP KERAS\n",
    "\n",
    "Pour ce workshop nous allons créer pas à pas un [réseau de neurones récurrent](https://fr.wikipedia.org/wiki/R%C3%A9seau_de_neurones_r%C3%A9currents) (RNN) à l'aide de la librairie Keras. Ce réseau nous permettra de prédire le prix des actions Google.\n",
    "\n",
    "Keras est une librairie qui permet de faire du deep learning en python, elle est basée sur une autre librairie développé par Google, [Tensorflow](https://www.tensorflow.org/).\n",
    "\n",
    "## Les imports des librairies\n",
    "\n",
    "Nous allons en premier lieu importer les librairies nécessaires pour ce workshop.\n",
    "\n",
    "Voici les imports que nous allons utiliser pour Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential       # use for NN\n",
    "from keras.layers import Dense            # use for NN\n",
    "from keras.layers import LSTM             # use for RNN\n",
    "from keras.layers import Dropout          # use for NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous avons les imports des outils nécessaires au traitement des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                               # use for array management\n",
    "import matplotlib.pyplot as plt                  # use for display data\n",
    "import pandas as pd                              # use for get csv data\n",
    "from sklearn.preprocessing import MinMaxScaler   # use for data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maintenant que tous nos outils sont prêts nous allons commencer le traitement de données.\n",
    "\n",
    "## Récupération et Traitement des données\n",
    "\n",
    "Nous allons récupérer les données des CSV à l'aide de pandas (les csv sont [ici](https://bit.ly/2wnGlkg) et [ici](https://bit.ly/2QseoRw))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the train dataset\n",
    "dataset_train = pd.read_csv(\"Google_Stock_Price_Train.csv\")\n",
    "train_set = dataset_train[[\"Open\"]].values\n",
    "\n",
    "# open the test dataset\n",
    "dataset_test = pd.read_csv(\"Google_Stock_Price_Test.csv\")\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values\n",
    "\n",
    "# data processing for scaling data in [0, 1] interval\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "train_set_scaled = sc.fit_transform(train_set)\n",
    "\n",
    "#divide data into xt (use for predict) and yt (the prediction result)\n",
    "xt = []\n",
    "yt = []\n",
    "\n",
    "for i in range(60, 1238):\n",
    "\txt.append(train_set_scaled[i-60:i, 0])\n",
    "\tyt.append(train_set_scaled[i, 0])\n",
    "xt = np.array(xt)\n",
    "yt = np.array(yt)\n",
    "\n",
    "xt = np.reshape(xt, (xt.shape[0], xt.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos données sont correctement traitées, nous allons pouvoir les exploiter.\n",
    "\n",
    "## Création du réseau de neurones\n",
    "\n",
    "Nous allons ici créer notre réseau de neurones à l'aide de Keras, voici le détail des différentes fonctions utilisées:\n",
    "\n",
    "| Fonction | détails |\n",
    "|: ----------|: -------|\n",
    "|Sequential()|creation de la base du réseau de neurones|\n",
    "|.add(LSTM...)|ajout d'une couche de neurones de type LSTM|\n",
    "|.add(Dropout())|probabilité qu'un neurone soit désactivé pour améliorer l'entrainement|\n",
    "|.add(Dense())|création d'une couche de densité x de neurones|\n",
    "|.compile()|compilation du réseau de neurones|\n",
    "|.fit()|entrainement du réseau de neurones|\n",
    "\n",
    "Vous pouvez modifier les valeurs pour arriver à un résultat plus pertinent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_training :\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 60, 45)            8460      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 60, 45)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 60, 45)            16380     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 60, 45)            0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 60, 45)            16380     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 60, 45)            0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50)                19200     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 60,471\n",
      "Trainable params: 60,471\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Created !\n"
     ]
    }
   ],
   "source": [
    "print(\"start_training :\")\n",
    "\n",
    "regressor = Sequential()\n",
    "\n",
    "# Units is the dimension of the inner cells\n",
    "# Return sequences defines if we can see the result of the hidden layers\n",
    "# Input shape defines the template of the input\n",
    "regressor.add(LSTM(units=45, return_sequences=True, input_shape=(xt.shape[1], 1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=45, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=45, return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(LSTM(units=50))\n",
    "regressor.add(Dropout(0.21))\n",
    "\n",
    "# This layer is the final layer, it MUST be 1 because we only wait 1 output\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "# During the compilation, the optimize and the loss define how the neural network is train.\n",
    "regressor.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "regressor.summary()\n",
    "\n",
    "print(\"Created !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le réseau créer, nous pouvons l'entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "# epochs define the number of training cicles\n",
    "# batch size is the number of inputs by epochs \n",
    "regressor.fit(xt, yt, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que le réseau de neuronne est entrainé, nous pouvons le tester avec nos données pour voir le résultat.\n",
    "\n",
    "## Prediction des actions de Google\n",
    "\n",
    "Maintenant nous allons utiliser le modèle entrainé précédemment pour prédire le prix des actions de Google du lendemain.\n",
    "\n",
    "### traitement des données de prédictions\n",
    "\n",
    "Nous commencerons par traiter les données pour pouvoir les utiliser lors de la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the total dataset for run the rnn\n",
    "dataset_total = pd.concat((dataset_train[\"Open\"], dataset_test[\"Open\"]), axis=0)\n",
    "\n",
    "# scale data for the prediction\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "inputs = inputs.reshape(-1, 1)\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "xtt = []\n",
    "\n",
    "# fill the prediction array\n",
    "for i in range(61, 101):\n",
    "    xtt.append(inputs[i-60:i, 0])\n",
    "xtt = np.array(xtt)\n",
    "\n",
    "xtt = np.reshape(xtt, (xtt.shape[0], xtt.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction\n",
    "\n",
    "Maintenant que tout est fin prêt nous allons pouvoir passer à la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of the stock price with .predict() function from Keras\n",
    "predict = regressor.predict(xtt)\n",
    "\n",
    "# transform the scaled data to the readable data\n",
    "predict = sc.inverse_transform(predict)\n",
    "\n",
    "print(real_stock_price)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne reste plus qu'a afficher les resultats sous forme de schéma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predict, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila ! Nous avons créé et entrainé notre réseau de neurone à l'aide de keras.\n",
    "\n",
    "Pour plus d'information sur Keras vous pouvez jeter un coup d'oeil [ici](https://keras.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
